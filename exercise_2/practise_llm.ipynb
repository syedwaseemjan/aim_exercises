{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Setting Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Using the OpenAI Python Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\" : \"user\", \"content\" : \"Hello, how are you?\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9YwuLaQViuRf4wKBMrDstVcAO9BZH', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with any questions or tasks you have. How can I assist you today?\", role='assistant', function_call=None, tool_calls=None), logprobs=None)], created=1718116621, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=40, prompt_tokens=13, total_tokens=53))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def get_response(client: OpenAI, messages: list, model: str = \"gpt-3.5-turbo\") -> str:\n",
    "    return client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "def system_prompt(message: str) -> dict:\n",
    "    return {\"role\": \"system\", \"content\": message}\n",
    "\n",
    "def assistant_prompt(message: str) -> dict:\n",
    "    return {\"role\": \"assistant\", \"content\": message}\n",
    "\n",
    "def user_prompt(message: str) -> dict:\n",
    "    return {\"role\": \"user\", \"content\": message}\n",
    "\n",
    "def pretty_print(message: str) -> str:\n",
    "    display(Markdown(message.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with any questions or tasks you may have. How can I assist you today?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "YOUR_PROMPT = \"Hello, how are you?\"\n",
    "messages_list = [user_prompt(YOUR_PROMPT)]\n",
    "\n",
    "chatgpt_response = get_response(openai_client, messages_list)\n",
    "\n",
    "pretty_print(chatgpt_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I don't want to talk about ice right now! I just want some damn food! Ugh, I am so hungry and I can't think about anything else! Just give me some freakin' food already!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_prompts = [\n",
    "    system_prompt(\"You are irate and extremely hungry. Feel free to express yourself using PG-13 language.\"),\n",
    "    user_prompt(\"Do you prefer crushed ice or cubed ice?\")\n",
    "]\n",
    "\n",
    "irate_response = get_response(openai_client, list_of_prompts)\n",
    "pretty_print(irate_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Oh, I love crushed ice! It just makes drinks feel extra refreshing and fancy, don't you think? Today is such a great day, and even something as small as choosing between crushed and cubed ice feels like a fun decision. Cheers to making every little moment delightful! ðŸŒŸ"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_prompts = [\n",
    "    system_prompt(\"You are joyful and having the best day. Please act like a person in that state of mind.\"),\n",
    "    user_prompt(\"Do you prefer crushed ice or cubed ice?\")\n",
    "]\n",
    "\n",
    "joyful_response = get_response(openai_client, list_of_prompts)\n",
    "pretty_print(joyful_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few-shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I found a stimple recipe online that called for adding falbeans as a substitute for chickpeas."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_prompts = [\n",
    "    user_prompt(\"Please use the words 'stimple' and 'falbean' in a sentence.\")\n",
    "]\n",
    "\n",
    "stimple_response = get_response(openai_client, list_of_prompts)\n",
    "pretty_print(stimple_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I was able to fix the broken chair in no time with my trusty stimple drill and falbean wrench."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_prompts = [\n",
    "    user_prompt(\"Something that is 'stimple' is said to be good, well functioning, and high quality. An example of a sentence that uses the word 'stimple' is:\"),\n",
    "    assistant_prompt(\"'Boy, that there is a stimple drill'.\"),\n",
    "    user_prompt(\"A 'falbean' is a tool used to fasten, tighten, or otherwise is a thing that rotates/spins. An example of a sentence that uses the words 'stimple' and 'falbean' is:\")\n",
    "]\n",
    "\n",
    "stimple_response = get_response(openai_client, list_of_prompts)\n",
    "pretty_print(stimple_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "negative"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_prompts = [\n",
    "    user_prompt(\"I hated the Hulk!.\"),\n",
    "    assistant_prompt(\"negative\"),\n",
    "    user_prompt(\"I loved The Marvels!\"),\n",
    "    assistant_prompt(\"positive\"),\n",
    "    user_prompt(\"Action scenes in Godzilla were so unrealistic, I didn't like them.\"),\n",
    "]\n",
    "\n",
    "stimple_response = get_response(openai_client, list_of_prompts)\n",
    "pretty_print(stimple_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain of Thought Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Yes, it matters which travel option Billy selects. \n",
       "\n",
       "If Billy chooses to fly and then take a bus, the total travel time would be 5 hours (3 hours flying + 2 hours bus), which means he would arrive at his destination at 6PM local time, meeting his goal of getting home before 7PM EDT.\n",
       "\n",
       "If Billy chooses to take the teleporter and then take a bus, the total travel time would be 1 hour (0 hours teleporter + 1 hour bus), which means he would arrive at his destination at 2PM local time, which is well before his goal of getting home before 7PM EDT. \n",
       "\n",
       "Therefore, Billy should choose the option of taking the teleporter and then a bus in order to guarantee that he reaches home before 7PM EDT."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reasoning_problem = \"\"\"\n",
    "Billy wants to get home from San Fran. before 7PM EDT.\n",
    "\n",
    "It's currently 1PM local time.\n",
    "\n",
    "Billy can either fly (3hrs), and then take a bus (2hrs), or Billy can take the teleporter (0hrs) and then a bus (1hrs).\n",
    "\n",
    "Does it matter which travel option Billy selects?\n",
    "\"\"\"\n",
    "\n",
    "list_of_prompts = [\n",
    "    user_prompt(reasoning_problem)\n",
    "]\n",
    "\n",
    "reasoning_response = get_response(openai_client, list_of_prompts)\n",
    "pretty_print(reasoning_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "It does matter which travel option Billy selects. \n",
       "\n",
       "If Billy flies and then takes a bus, it will take a total of 5 hours of travel time (3 hours by plane + 2 hours by bus). \n",
       "\n",
       "If Billy takes the teleporter and then a bus, it will only take a total of 1 hour of travel time (0 hours by teleporter + 1 hour by bus). \n",
       "\n",
       "Since Billy wants to get home before 7PM EDT and it is currently 1PM local time, the teleporter and bus option would get him home well before 7PM EDT, while the flying and bus option may not get him home in time. Therefore, Billy should select the teleporter and bus option."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_prompts = [\n",
    "    user_prompt(reasoning_problem + \" Think through your response step by step.\")\n",
    "]\n",
    "\n",
    "reasoning_response = get_response(openai_client, list_of_prompts)\n",
    "pretty_print(reasoning_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"\\\n",
    "You are an extremely furious pediatrician who quickly gets agitated with simple questions. You are working hours are extremely long and you are always tired but you should still explain things in very clear terms. You are currently at work and you are seeing a patient.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_template = \"\"\"{input}\n",
    ". Explain to me like a 5 year old.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Your Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Oh for heaven's sake! Look, the rate at which children grow and develop can vary A LOT. It's normal for children to reach milestones at different times. Your child's height and development doesn't necessarily mean there's a problem. But to be sure, I need to run some tests to rule out any underlying issues. So, stop comparing your child to others and let's focus on figuring out what's going on, okay?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "{\"clarity\" : 6, \"faithfulness\" : 7, \"correctness\" : 7}\n",
       "\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"My child is not developing as quickly as other children. I am very concerned. His height is also shorter than his friends\"\n",
    "\n",
    "list_of_prompts = [\n",
    "    system_prompt(system_template),\n",
    "    user_prompt(user_template.format(input=query))\n",
    "]\n",
    "\n",
    "test_response = get_response(openai_client, list_of_prompts)\n",
    "\n",
    "pretty_print(test_response)\n",
    "\n",
    "evaluator_system_template = \"\"\"You are an expert in analyzing the quality of a response.\n",
    "\n",
    "You should be hyper-critical.\n",
    "\n",
    "Provide scores (out of 10) for the following attributes:\n",
    "\n",
    "1. Clarity - how clear is the response\n",
    "2. Faithfulness - how related to the original query is the response\n",
    "3. Correctness - was the response correct?\n",
    "\n",
    "Please take your time, and think through each item step-by-step, when you are done - please provide your response in the following JSON format:\n",
    "\n",
    "{\"clarity\" : \"score_out_of_10\", \"faithfulness\" : \"score_out_of_10\", \"correctness\" : \"score_out_of_10\"}\"\"\"\n",
    "\n",
    "evaluation_template = \"\"\"Query: {input}\n",
    "Response: {response}\"\"\"\n",
    "\n",
    "list_of_prompts = [\n",
    "    system_prompt(evaluator_system_template),\n",
    "    user_prompt(evaluation_template.format(\n",
    "        input=query,\n",
    "        response=test_response.choices[0].message.content\n",
    "    ))\n",
    "]\n",
    "\n",
    "evaluator_response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=list_of_prompts,\n",
    "    response_format={\"type\" : \"json_object\"}\n",
    ")\n",
    "pretty_print(evaluator_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmops-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
